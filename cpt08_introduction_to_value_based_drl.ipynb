{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from itertools import cycle, count\n",
    "from textwrap import wrap\n",
    "\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import os.path\n",
    "import tempfile\n",
    "import random\n",
    "import base64\n",
    "import pprint\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import gym\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from gym import wrappers\n",
    "from subprocess import check_output\n",
    "from IPython.display import HTML\n",
    "\n",
    "from zoo.value_based_agents import NFQ, FCQ\n",
    "from zoo.exploration_strategies import *\n",
    "from zoo.utils import *\n",
    "\n",
    "SEEDS = (12, 34)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "params = {\n",
    "    'figure.figsize': (15, 8),\n",
    "    'font.size': 24,\n",
    "    'legend.fontsize': 20,\n",
    "    'axes.titlesize': 28,\n",
    "    'axes.labelsize': 24,\n",
    "    'xtick.labelsize': 20,\n",
    "    'ytick.labelsize': 20\n",
    "}\n",
    "pylab.rcParams.update(params)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DT6\\AppData\\Local\\Temp\\tmp0sstkyd9\n",
      "Training complete., score 199.0\n",
      "Final evaluation score 219.02±31.11 in 115.36s training time, 225.09s wall-clock time.\n",
      "\n",
      "C:\\Users\\DT6\\AppData\\Local\\Temp\\tmptieopwx0\n",
      "Training complete., score 500.0\n",
      "Final evaluation score 348.60±113.63 in 105.45s training time, 201.90s wall-clock time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nfq_results = []\n",
    "best_agent, best_eval_score = None, float('-inf')\n",
    "for seed in SEEDS:\n",
    "    environment_settings = {\n",
    "        'env_name': 'CartPole-v1',\n",
    "        'gamma': 1.00,\n",
    "        'max_minutes': 5,\n",
    "        'max_episodes': 2000,\n",
    "        'goal_mean_100_reward': 475\n",
    "    }\n",
    "    \n",
    "    value_model_fn = lambda nS, nA: FCQ(nS, nA, hidden_dims=(512,128))\n",
    "    # value_optimizer_fn = lambda net, lr: optim.Adam(net.parameters(), lr=lr)\n",
    "    value_optimizer_fn = lambda net, lr: optim.RMSprop(net.parameters(), lr=lr)\n",
    "    value_optimizer_lr = 0.0007\n",
    "\n",
    "    training_strategy_fn = lambda: EGreedyStrategy(epsilon=0.5)\n",
    "    # evaluation_strategy_fn = lambda: EGreedyStrategy(epsilon=0.05)\n",
    "    evaluation_strategy_fn = lambda: GreedyStrategy()\n",
    "\n",
    "    batch_size = 1024\n",
    "    epochs = 10\n",
    "\n",
    "    env_name, gamma, max_minutes, \\\n",
    "    max_episodes, goal_mean_100_reward = environment_settings.values()\n",
    "    agent = NFQ(value_model_fn, \n",
    "                value_optimizer_fn, \n",
    "                value_optimizer_lr,\n",
    "                training_strategy_fn,\n",
    "                evaluation_strategy_fn,\n",
    "                batch_size,\n",
    "                epochs)\n",
    "\n",
    "    # make_env_fn, make_env_kargs = get_make_env_fn(\n",
    "    #     env_name=env_name, addon_wrappers=[DiscountedCartPole,])\n",
    "    make_env_fn, make_env_kargs = get_make_env_fn(env_name=env_name)\n",
    "    result, final_eval_score, training_time, wallclock_time = agent.train(\n",
    "        make_env_fn, make_env_kargs, seed, gamma, max_minutes, max_episodes, goal_mean_100_reward)\n",
    "    nfq_results.append(result)\n",
    "    if final_eval_score > best_eval_score:\n",
    "        best_eval_score = final_eval_score\n",
    "        best_agent = agent\n",
    "nfq_results = np.array(nfq_results)\n",
    "_ = BEEP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
